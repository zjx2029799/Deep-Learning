{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = np.loadtxt('bbs-train.txt')\n",
    "label = np.loadtxt('label-train.txt')\n",
    "# initialize the dataset\n",
    "image_train = image[:4500]\n",
    "image_val = image[4500:]\n",
    "labels = np.zeros((len(label),2))\n",
    "for i in range(len(label)):\n",
    "    if label[i,1] == 0:\n",
    "        labels[i] = [0.0, 1.0]\n",
    "    if label[i,1] == 1:\n",
    "        labels[i] = [1.0, 0.0]\n",
    "\n",
    "label_train = labels[:4500]\n",
    "label_val = labels[4500:]\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.58\n",
      "step 100, training accuracy 0.38\n",
      "step 200, training accuracy 0.74\n",
      "step 300, training accuracy 0.78\n",
      "step 400, training accuracy 0.68\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.86\n",
      "step 700, training accuracy 0.68\n",
      "step 800, training accuracy 0.84\n",
      "step 900, training accuracy 0.62\n",
      "step 1000, training accuracy 0.7\n",
      "step 1100, training accuracy 0.9\n",
      "step 1200, training accuracy 0.72\n",
      "step 1300, training accuracy 0.9\n",
      "step 1400, training accuracy 0.84\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 0.92\n",
      "step 1700, training accuracy 0.8\n",
      "step 1800, training accuracy 0.8\n",
      "step 1900, training accuracy 0.86\n",
      "training complete!\n",
      "test accuracy 0.978261\n",
      "[[ -5.19537170e+02   1.33170410e+02]\n",
      " [ -3.43377856e+03   2.99168213e+03]\n",
      " [ -1.98657312e+03   2.08800195e+03]\n",
      " [ -1.66722791e+03   1.33688843e+03]\n",
      " [ -7.03347107e+02   5.94187195e+02]\n",
      " [ -1.92773743e+03   2.36374756e+03]\n",
      " [ -4.50813171e+02   4.92204285e+01]\n",
      " [ -6.76065979e+02   4.14269196e+02]\n",
      " [ -4.18180566e+03   5.05023779e+03]\n",
      " [ -5.90607227e+03   6.26868604e+03]\n",
      " [ -1.04770374e+03   1.19799988e+03]\n",
      " [ -2.12502954e+03   1.96726404e+03]\n",
      " [ -3.71199768e+02   2.08359894e+02]\n",
      " [  5.16893494e+02  -2.80129370e+03]\n",
      " [ -4.03263770e+03   3.06119995e+03]\n",
      " [ -1.41826746e+03   1.20061694e+03]\n",
      " [ -2.13480054e+03   2.11607275e+03]\n",
      " [ -4.43193756e+02   1.46650610e+01]\n",
      " [ -3.81311987e+03   3.17364355e+03]\n",
      " [ -8.60236511e+02   9.44475403e+02]\n",
      " [ -1.37349475e+03   1.32875256e+03]\n",
      " [ -2.95196313e+03   1.66381360e+03]\n",
      " [ -1.88532434e+03   1.76050208e+03]\n",
      " [ -2.36721460e+03   2.22976904e+03]\n",
      " [ -1.32230139e+03   1.22844348e+03]\n",
      " [ -3.70295776e+03  -7.87675858e+01]\n",
      " [ -3.47145557e+03   2.60804150e+03]\n",
      " [ -1.28420300e+03   1.32715833e+03]\n",
      " [ -1.67034927e+02  -5.64866699e+02]\n",
      " [ -2.77841040e+03   2.08928516e+03]\n",
      " [ -4.17748169e+02   2.75681335e+02]\n",
      " [ -1.74529512e+04  -1.67262531e+05]\n",
      " [ -3.69192651e+03  -2.55156484e+04]\n",
      " [ -7.03502686e+03  -1.18611963e+04]\n",
      " [ -7.95212952e+02   6.38937561e+02]\n",
      " [ -4.18570312e+03   3.62315674e+03]\n",
      " [ -2.45159741e+03   8.52671021e+02]\n",
      " [ -1.80033850e+03   1.82015564e+03]\n",
      " [ -2.17063965e+03   2.06328418e+03]\n",
      " [ -2.58196118e+03   2.02212292e+03]\n",
      " [ -1.17736584e+03   4.39686127e+02]\n",
      " [ -9.39467529e+02   4.92917267e+02]\n",
      " [ -9.82155212e+02   3.74735626e+02]\n",
      " [ -3.10900220e+03   3.29147729e+03]\n",
      " [ -4.74693701e+03   3.69354883e+03]\n",
      " [ -8.89858826e+02   7.84168884e+02]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None,800])\n",
    "y = tf.placeholder(tf.float32, shape= [None,2])\n",
    "\n",
    "W = tf.Variable(tf.zeros([800,2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "y_ = tf.matmul(x, W) + b\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "## [1, 2, 2, 1]  1: input 像素 1 represents channel  1: represent output channel\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# first layer\n",
    "## The convolution will compute 32 features for each 5x5 patch\n",
    "## The first two dimensions are the patch size, the next is the number of input channels, \n",
    "## and the last is the number of output channels\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# reshape\n",
    "## the second and third dimensions corresponding to image width and height, \n",
    "## and the final dimension corresponding to the number of color channels.\n",
    "x_image = tf.reshape(x, [-1, 40, 20, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# second layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "## now the dimension will reduce to 10 * 5  and 64 features, and we give 1024 nueron for \n",
    "## fully connected neuron network\n",
    "W_fc1 = weight_variable([10 * 5 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "## finally flatten the input into fully connected neuron network\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 10 * 5 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## add our softmax layer for regression above\n",
    "W_fc2 = weight_variable([1024, 2])\n",
    "b_fc2 = bias_variable([2])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# *******************************************************************\n",
    "# DONT Run it here or it will crash the computer. Run it on unix env.\n",
    "# *******************************************************************\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2000):\n",
    "        batch_x, batch_y = next_batch(50, image_train, label_train)\n",
    "        if i%100 == 0:\n",
    "            # for every step except for the output in training process, we wond't use dropout \n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "        # without output, we just use dropout to train the data\n",
    "        optimizer.run(feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "\n",
    "    print(\"training complete!\")\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: image_val, y: label_val, keep_prob: 1.0}))\n",
    "    y_pred = sess.run(y_conv, feed_dict={x: image_val, keep_prob: 1.0})\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(46):\n",
    "    if data[i,0] > data[i,1]:\n",
    "        y_pred[i,0] = 1.0\n",
    "        y_pred[i,1] = 0.0\n",
    "    else:\n",
    "        y_pred[i,0] = 0.0\n",
    "        y_pred[i,1] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [False, False],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(y_pred, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   1.33170410e+02],\n",
       "       [ -3.43377856e+03,   2.99168213e+03],\n",
       "       [ -1.98657312e+03,   2.08800195e+03],\n",
       "       [ -1.66722791e+03,   1.33688843e+03],\n",
       "       [ -7.03347107e+02,   5.94187195e+02],\n",
       "       [ -1.92773743e+03,   2.36374756e+03],\n",
       "       [ -4.50813171e+02,   4.92204285e+01],\n",
       "       [ -6.76065979e+02,   4.14269196e+02],\n",
       "       [ -4.18180566e+03,   5.05023779e+03],\n",
       "       [ -5.90607227e+03,   6.26868604e+03],\n",
       "       [ -1.04770374e+03,   1.19799988e+03],\n",
       "       [ -2.12502954e+03,   1.96726404e+03],\n",
       "       [ -3.71199768e+02,   2.08359894e+02],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [ -4.03263770e+03,   3.06119995e+03],\n",
       "       [ -1.41826746e+03,   1.20061694e+03],\n",
       "       [ -2.13480054e+03,   2.11607275e+03],\n",
       "       [ -4.43193756e+02,   1.46650610e+01],\n",
       "       [ -3.81311987e+03,   3.17364355e+03],\n",
       "       [ -8.60236511e+02,   9.44475403e+02],\n",
       "       [ -1.37349475e+03,   1.32875256e+03],\n",
       "       [ -2.95196313e+03,   1.66381360e+03],\n",
       "       [ -1.88532434e+03,   1.76050208e+03],\n",
       "       [ -2.36721460e+03,   2.22976904e+03],\n",
       "       [ -1.32230139e+03,   1.22844348e+03],\n",
       "       [ -3.70295776e+03,  -7.87675858e+01],\n",
       "       [ -3.47145557e+03,   2.60804150e+03],\n",
       "       [ -1.28420300e+03,   1.32715833e+03],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [ -2.77841040e+03,   2.08928516e+03],\n",
       "       [ -4.17748169e+02,   2.75681335e+02],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [ -7.95212952e+02,   6.38937561e+02],\n",
       "       [ -4.18570312e+03,   3.62315674e+03],\n",
       "       [ -2.45159741e+03,   8.52671021e+02],\n",
       "       [ -1.80033850e+03,   1.82015564e+03],\n",
       "       [ -2.17063965e+03,   2.06328418e+03],\n",
       "       [ -2.58196118e+03,   2.02212292e+03],\n",
       "       [ -1.17736584e+03,   4.39686127e+02],\n",
       "       [ -9.39467529e+02,   4.92917267e+02],\n",
       "       [ -9.82155212e+02,   3.74735626e+02],\n",
       "       [ -3.10900220e+03,   3.29147729e+03],\n",
       "       [ -4.74693701e+03,   3.69354883e+03],\n",
       "       [ -8.89858826e+02,   7.84168884e+02]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
